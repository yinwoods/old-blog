---
layout: post
title: python爬虫统计豆瓣观影记录
categories: ['coding']
tags: ['python', '爬虫']
published: True
img: 50

---

说来大四这一年真的看了好多电影啊。。。因为平时有用豆瓣电影记录自己已看电影的习惯，而且博客上也维护了一个影单，所以趁着这几天有时间就想着干脆写一个统计自己大四这一年观影记录的小程序吧！

打算最终分三种方式统计信息：
    
- 统计不同类型的电影数目并绘制柱状图

- 统计不同语言的电影数目并绘制饼状图
    
- 统计每个月的观影数目并绘制趋势图

因此需要获取的信息电影信息有：电影名、观影时间、电影类型、电影语言；另外后期可能还想统计其他信息，干脆把评分、自己的评论、电影导演和制片国家/地区都爬取下来。
    

说干就干，首先设计一下程序的逻辑架构，具体分为以下几步：

    1. 获取博客已看影单上的所有电影名，并存入数据库的movie表中；
    
    2. 利用爬虫爬取豆瓣电影上自己的观影记录，包括（电影名、评分、观影时间、自己的评论、电影类型、电影导演、制片国家/地区 以及 电影语言），获取这些信息后写入数据库的douban_movies表；
    
    3. 利用douban_movies表与movie表left join，并更新movie表出电影名以外的其他信息；
    
    4. 通过相关模块包把数据库中的数据写入excel表中并生成图表；
    
    5. 将生成的图表转换为图片并保存；
    
这个思路是通的，而且看起来操作起来难度也不大。在这里要解释一下为什么我不直接使用douban_movies表来统计，而要基于博客的观影记录来统计，原因在于我是去年十一月份才真正意义上开始使用豆瓣电影标记功能的，因此一些很久以前（like:小时候^_^）看过的电影也在豆瓣上标记下来了，所以这部分数据是要剔除的。

当然对于很早之前就开始使用豆瓣电影的朋友来说，只需对程序稍加改造即可生成自己的观影记录了。

下面就按照逻辑架构开始编写程序吧！

#### 1. 获取博客上已看影单的所有电影名，并存入数据库中的movie表
    
虽然简单，但是还是要说下思路，以影单页面的url作为入口，爬虫访问后利用beautifulsoup解析文档树，提取所有的电影名并将电影名插入数据表中，为了防止每次运行程序不会插入重复数据，插入之前需要判重操作。代码如下：

{% highlight python %}

#获取url 对应 HTML 源码
def get_html(self, url):
    request = urllib.request.Request(url)

    try: #代理：110.81.238.173:8088
        proxy_support = urllib.request.ProxyHandler({'http': '110.81.238.173:8088'})
        opener = urllib.request.build_opener(proxy_support)
        urllib.request.install_opener(opener)

        page = urllib.request.urlopen(request)

        if page.headers.get('Content-Encoding') == 'gzip':
            return zlib.decompress(page.read(), 16+zlib.MAX_WBITS).decode('gbk', 'ignore')
        else:
            return page.read().decode(page.headers.get_content_charset(), 'ignore')
    #异常处理
    except urllib.request.HTTPError as e:
        print('HTTPERROR: ', str(e))
        return urllib.request.HTTPError
    except http.client.HTTPException as e:
        print('http.client.HTTPException: ', str(e))
        return http.client.HTTPException

#获取电影名并写入数据库movie中
def get_movies(self, url_lists):

    for url in url_lists:
        html_doc = BeautifulSoup(self.get_html(url), 'html.parser')
        div_lists = html_doc.select('#content > div > div > a > div')
        for div in div_lists:

            movie_name = div.getText()

            #查重
            query = 'SELECT COUNT(*) FROM movie WHERE movie_name = %s'
            self.cursor.execute(query, (movie_name,))
            self.conn.commit()
            res = self.cursor.fetchall()
            if not res[0][0] == 0:
                continue

            print(movie_name)

            #插入
            query = 'INSERT INTO movie(movie_name) VALUES (%s)'
            self.cursor.execute(query, (movie_name,))
            self.conn.commit()
{% endhighlight %}
    
#### 2. 利用爬虫爬取豆瓣电影上的观影信息

依然是同样的套路，首先找到这些信息的入口，找到url:https://movie.douban.com/people/用户名/collect?sort=time&amp;start=0&amp;filter=all&amp;mode=list&amp;tags_sort=count，发现链接中不包含页码，所以考虑每次获取下一页的url加入待爬队列直到队列为空（其实就是广度优先搜索~~~），代码如下：
    
{% highlight python %}
#从豆瓣上获取我的观影信息
def get_douban_infos(self, username):

    url_que = queue.Queue()
    url_que.put('https://movie.douban.com/people/' + username + '/collect?sort=time&amp;start=0&amp;filter=all&amp;mode=list&amp;tags_sort=count')
    while not url_que.empty():
        url = url_que.get()
        #爬取第一页
        html_doc = BeautifulSoup(self.get_html(url), 'html.parser')

        #获取下一页链接
        next_url = html_doc.select('#content > div.grid-16-8.clearfix > div.article > div.paginator > span.next > a')
        
        #如果有下一页则加入待爬队列
        if len(next_url) > 0:
            next_url = next_url[0]['href']
            url_que.put(next_url)

        html_doc = BeautifulSoup(self.get_html(url), 'html.parser')
        li_lists = html_doc.select('#content > div')[1].select('div.article > ul > li')

        for li in li_lists:

            a_label = li.select('div.item-show > div > a')[0]

            movie_name = a_label.getText().strip()
            movie_name = movie_name.split('/')[0].strip()

            #去重
            query = 'SELECT COUNT(*) FROM douban_movie WHERE movie_name = (%s)'
            self.cursor.execute(query, (movie_name,))
            self.conn.commit()
            res = self.cursor.fetchall()
            if not res[0][0] == 0:
                continue
            
            #电影类型等信息到详情页中获取更容易
            movie_detail_url = a_label['href']
            print(movie_detail_url)
            try:
                movie_info = self.get_movie_infos(movie_detail_url)
            except TypeError as e:
                print(str(e))
                print(movie_name)
                continue
            
            #利用正则表达式提取评分，注意有些电影未打评分的情况
            rate = li.select('div.item-show > div')[1].select('span')
            if len(rate) == 0:
                rate = ''
            else:
                rate = str(rate[0]['class'])
                regx = re.compile('(\d)')
                rate = regx.findall(rate)[0]

            watch_time = li.select('div.item-show > div')[1].getText().strip()

            comment = li.select('div.comment')
            #如果有评论
            if len(comment) > 0:
                comment = comment[0].getText().strip()
                if not comment.find('(1 有用)') == -1:
                    comment = comment.split(' ')[0].strip()
            else:
                comment = ''

            print(movie_info)

            movie_types = movie_info['类型']
            movie_language = movie_info['语言']
            movie_country = movie_info['制片国家/地区']
            movie_director = movie_info['导演']

            print(comment)
            query = 'INSERT INTO douban_movie(movie_name, rate, watch_time, comment, movie_types, movie_language, movie_country, movie_director) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)'
            self.cursor.execute(query, (movie_name, rate, watch_time, comment, movie_types, movie_language, movie_country, movie_director))
            self.conn.commit()
    return
{% endhighlight %}
    
在从详情页获取信息的过程中，可以采用一些技巧方便我们提取出自己想要的信息（例如代码中把信息以dict的形式返回，方便解析），代码如下：

{% highlight python %}
#从电影详情页获取电影类型，结果返回一个dict
def get_movie_infos(self, url):

    html_doc = BeautifulSoup(self.get_html(url), 'html.parser')
    div_info = html_doc.select('#info')[0].getText().strip().split('\n')
    res_info = {}
    for div in div_info:
        div = div.split(': ')
        if div[0] == '导演':
            res_info.update({'导演' : ','.join(div[1:])})
        elif div[0] == '制片国家/地区':
            res_info.update({'制片国家/地区' : ','.join(div[1:])})
        elif div[0] == '语言':
            res_info.update({'语言' : ','.join(div[1:])})
        elif div[0] == '类型':
            res_info.update({'类型' : ','.join(div[1:])})
    return res_info
{% endhighlight %}
    
#### 3. 利用douban_movies表与movie表left join，并更新movie表出电影名以外的其他信息；
    
这一步操作就比较简单了，其实就是对数据表的操作，但是因为自己博客上电影命名不规范的原因，因此还要做一个匹配表来处理明明不规范的case，代码如下所示：
    
{% highlight python %}
#从数据库中读取电影名并通过豆瓣查询
def search_movies(self, username='yinwoods'):
    query = 'SELECT movie_name FROM movie'
    self.cursor.execute(query)
    self.conn.commit()
    res = self.cursor.fetchall()

    self.get_douban_infos(username)

    movie_dicts = {
        '玩具总动员1' : '玩具总动员',
        '蝙蝠侠之黑暗骑士崛起' : '蝙蝠侠：黑暗骑士崛起',
        '我和厄尔及将死的女孩' : '我和厄尔以及将死的女孩',
        '寄生兽 完结篇' : '寄生兽：完结篇',
        '蜡笔小新 搬家物语' : '蜡笔小新：我的搬家物语 仙人掌大袭击',
        '歌曲改变人生' : '再次出发之纽约遇见你',
        '复仇者联盟2' : '复仇者联盟2：奥创纪元',
        '蝙蝠侠·黑暗骑士' : '蝙蝠侠：黑暗骑士',
        'Inside Out' : '头脑特工队',
        'Detachment' : '超脱',
        '心之谷' : '侧耳倾听',
        'Minions' : '小黄人大眼萌',
        '谍中谍5' : '碟中谍5：神秘国度',
        '钢琴师' : '钢琴家',
        '灵异第六感' : '第六感',
        '我是谁' : '我是谁：没有绝对安全的系统',
        '七号房的礼物' : '7号房的礼物',
        '小森林冬春篇' : '小森林 冬春篇',
        '本杰明巴顿奇事' : '本杰明·巴顿奇事',
        '进击的巨人' : '进击的巨人真人版：前篇',
        '王牌特工' : '王牌特工：特工学院',
        '海贼王之3D2Y' : '海贼王15周年纪念特别篇——幻之篇章「3D2Y 跨越艾斯之死！与路飞...',
        '小森林之夏秋篇' : '小森林 夏秋篇',
        '模仿游戏{祖师爷}' : '模仿游戏',
        '疯狂的麦克斯' : '疯狂的麦克斯4：狂暴之路',
        '重返二十岁' : '重返20岁',
        '哆啦a梦之伴我同行' : '哆啦A梦：伴我同行',
        '阴儿房' : '潜伏'
    }

    for movie in res:
        movie_name = movie[0]
        new_movie_name = movie_name

        if movie_name in movie_dicts:
            new_movie_name = movie_dicts[movie_name]

        query = 'SELECT rate, watch_time, comment, movie_types, movie_language, movie_country, movie_director FROM douban_movie WHERE movie_name = (%s)'
        self.cursor.execute(query, (new_movie_name,))
        self.conn.commit()
        res = self.cursor.fetchall()

        try:
            [rate, watch_time, comment, movie_types, movie_language, movie_country, movie_director] = res[0]
        except IndexError as e:
            print(movie_name)
            continue

        watch_time = str(watch_time).split(' ')[0]
        query = 'UPDATE movie SET rate = %s, watch_time = %s, comment = %s, movie_types = %s, movie_language = %s, movie_country = %s, movie_director = %s WHERE movie_name = %s'
        self.cursor.execute(query, (rate, watch_time, comment, movie_types, movie_language, movie_country, movie_director, movie_name))
        self.conn.commit()
    return
{% endhighlight %}
    
#### 4. 通过相关模块包把数据库中的数据写入excel表中并生成图表；
    
现在我们已经获得了自己的观影数据并存入数据库中，后面要做的就是把数据统计信息写入excel表了，这里推荐[xlsxwriter模块](http://xlsxwriter.readthedocs.io/#)（PS：其实最开始就是想通过这个程序学习下xlsxwriter模块23333），[xlsxwriter模块](http://xlsxwriter.readthedocs.io/#)的主要功能是实现了python对excel表的操作。但是xlsxwriter的一个问题是不能读取excel的数据，往往需要结合pandas模块才能发挥最大作用。当然这里我们只需要写入功能，例如统计不同类型电影数目并制作柱状图的代码如下：
    
{% highlight python %}
#将电影类型分类展示在柱状图中并统计数量
def show_types_in_column(self, workbook):

    worksheet = workbook.add_worksheet()

    chart = workbook.add_chart({'type' : 'column'})

    query = 'SELECT movie_name, movie_types FROM movie'
    self.cursor.execute(query)
    self.conn.commit()
    movies_lists = self.cursor.fetchall()

    movie_types_dict = {}

    for movie in movies_lists:
        movie_name, movie_types = movie
        types = movie_types.split('/')
        for type in types:
            type = type.strip()
            if type in movie_types_dict:
                movie_types_dict[type] += 1
            else:
                movie_types_dict.update({type : 1})

    # Add table data
    table_data = [['类型', '片数'],]
    for key, val in movie_types_dict.items():
        table_data.append([key, val])

    type = '类型'
    num = '数目'
    worksheet.write_column('A1', type)
    worksheet.write_column('B1', num)
    worksheet.write_column('A2', movie_types_dict.keys())
    worksheet.write_column('B2', movie_types_dict.values())

    chart.add_series({'name' : '影片数目',
                      'categories' : ['Sheet1', 1, 0, 1+len(movie_types_dict.keys()), 0],
                      'values' : ['Sheet1', 1, 1, 1+len(movie_types_dict.values()), 1],
                      'color' : 'red',
                      'data_labels' : {'value' : True}})

    #设置X轴属性
    chart.set_x_axis({
        'name' : '影片类型',
        'name_font' : {'size' : 14, 'bold' : False},
        'num_font' : {'size' : 12},
        'line' : {'none' : True},
        'major_gridlines' : {
            'visible' : True,
            'line' : {'width' : 1.5, 'dash_type' : 'dash'}
        },
        'text_axis' : True
    })

    #设置长宽
    chart.set_size({
        'x_scale' : 2.5,
        'y_scale' : 2
    })

    #设置标题
    chart.set_title({
        'name' : '15/07/01 - 16/06/30 观影类型统计'
    })

    #设置属性块
    chart.set_legend({
        'position' : 'left'
    })

    #图下方显示表格
    chart.set_table({
        'show_keys' : True,
        'font' : {'size' : 12}
    })

    worksheet.insert_chart('C1', chart)
{% endhighlight %}

#### 5.将生成的图表转换为图片并保存；

这里把excel表中的chart转为图片通过VBA编程可以比较容易地实现，但是我们的目标是通过python来实现，经过搜索了解到可以使用windows的扩展包pywin32模块来实现这个功能，具体的代码源于网上的开源代码，其实难度倒是没有，主要难点在于api的使用。具体代码如下：
    
{% highlight python %}
from win32com.client import Dispatch
import os
import pythoncom
class Pyxlchart(object):
    """
    This class exports charts in an Excel Spreadsheet to the FileSystem
    win32com libraries are required.
    """
    def __init__(self):
        pythoncom.CoInitialize()
        self.WorkbookDirectory = ''
        self.WorkbookFilename = ''
        self.GetAllWorkbooks = False
        self.SheetName = ''
        self.ChartName = ''
        self.GetAllWorkbookCharts = False
        self.GetAllWorksheetCharts = False
        self.ExportPath = ''
        self.ImageFilename = ''
        self.ReplaceWhiteSpaceChar = '_'
        self.ImageType = 'jpg'

    def __del__(self):
        pass

    def start_export(self):
        if self.WorkbookDirectory == '':
            return "WorkbookDirectory not set"
        else:
            self._export()

    def _export(self):
        """
        Exports Charts as determined by the settings in class variabels.
        """
        excel = Dispatch("excel.application")
        excel.Visible = False
        wb = excel.Workbooks.Open(os.path.join(self.WorkbookDirectory ,self.WorkbookFilename))
        self._get_Charts_In_Worksheet(wb,self.SheetName,self.ChartName)
        wb.Close(False)
        excel.Quit()

    def _get_Charts_In_Worksheet(self,wb,worksheet = "", chartname = ""):
        if worksheet != "" and chartname != "":
            sht = self._change_sheet(wb,worksheet)
            cht = sht.ChartObjects(chartname)
            self._save_chart(cht, sht.Name)
            return
        if worksheet == "":
            for sht in wb.Worksheets:
                for cht in sht.ChartObjects():
                    if chartname == "":
                        self._save_chart(cht, sht.Name)
                    else:
                        if chartname == cht.Name:
                            self._save_chart(cht, sht.Name)
        else:
            sht = wb.Worksheets(worksheet)
            for cht in sht.ChartObjects():
                if chartname == "":
                    self._save_chart(cht, sht.Name)
                else:
                    if chartname == cht.Name:
                        self._save_chart(cht, sht.Name)

    def _change_sheet(self,wb,worksheet):
        try:
            return wb.Worksheets(worksheet)
        except:
            raise NameError('Unable to Select Sheet: ' + worksheet + ' in Workbook: ' + wb.Name)

    def _save_chart(self,chartObject, sheetnamme):
        imagename = self._get_filename(chartObject.Name, sheetnamme)
        savepath = os.path.join(self.ExportPath,imagename)
        print(savepath)
        chartObject.Chart.Export(savepath,self.ImageType)

    def _get_filename(self, chartname, sheetnamme):
        """
        Replaces white space in self.WorkbookFileName with the value given in self.ReplaceWhiteSpaceChar
        If self.ReplaceWhiteSpaceChar is an empty string then self.WorkBookFileName is left as is
        """
        if self.ImageFilename == '':
            self.ImageFilename == chartname
        if self.ReplaceWhiteSpaceChar != '':
            chartname.replace(' ',self.ReplaceWhiteSpaceChar)
        if self.ImageFilename != "":
            return self.ImageFilename + "_" + sheetnamme + "_" + chartname + "." + self.ImageType
        else:
            return sheetnamme + "_" + chartname + '.' + self.ImageType

def main():
    xl = Pyxlchart()
    xl.WorkbookDirectory = "G:\\"
    xl.WorkbookFilename = "chart.xlsx"
    xl.SheetName = ""
    xl.ImageFilename = "Movies"
    xl.ExportPath = "G:\\"
    xl.ChartName = ""
    xl.start_export()

if __name__ == "__main__":
    main()
{% endhighlight %}
    
最后完整的代码在这里：[观影统计代码](https://github.com/yinwoods/show_movies_info)
    
另外，也开发了删减版，只需输入豆瓣用户名即可生成相应的观影统计信息（对这个功能感兴趣的朋友应该更多吧）。代码如下：

{% highlight python %}
import re
import zlib
import queue
import urllib
import pymysql
import datetime
import xlsxwriter
import http.client
import urllib.request
from bs4 import BeautifulSoup

class Crawler():

    def __init__(self):
        self.conn = pymysql.connect(user='root', passwd='root', host='localhost', port=3306, db='movies', charset='UTF8')
        self.cursor = self.conn.cursor()
        self.carShouYeUrlSet = []

    def __del__(self):
        self.cursor.close()
        self.conn.close()

    #获取url 对应 HTML 源码
    def get_html(self, url):
        request = urllib.request.Request(url)

        try: #代理：110.81.238.173:8088
            proxy_support = urllib.request.ProxyHandler({'http': '110.81.238.173:8088'})
            opener = urllib.request.build_opener(proxy_support)
            urllib.request.install_opener(opener)

            page = urllib.request.urlopen(request)

            if page.headers.get('Content-Encoding') == 'gzip':
                return zlib.decompress(page.read(), 16+zlib.MAX_WBITS).decode('gbk', 'ignore')
            else:
                return page.read().decode(page.headers.get_content_charset(), 'ignore')

        except urllib.request.HTTPError as e:
            print('HTTPERROR: ', str(e))
            return urllib.request.HTTPError
        except http.client.HTTPException as e:
            print('http.client.HTTPException: ', str(e))
            return http.client.HTTPException

    #从电影详情页获取电影类型
    def get_movie_infos(self, url):

        html_doc = BeautifulSoup(self.get_html(url), 'html.parser')
        div_info = html_doc.select('#info')[0].getText().strip().split('\n')
        res_info = {}
        for div in div_info:
            div = div.split(': ')
            if div[0] == '导演':
                res_info.update({'导演' : ','.join(div[1:])})
            elif div[0] == '制片国家/地区':
                res_info.update({'制片国家/地区' : ','.join(div[1:])})
            elif div[0] == '语言':
                res_info.update({'语言' : ','.join(div[1:])})
            elif div[0] == '类型':
                res_info.update({'类型' : ','.join(div[1:])})
        return res_info

    #从豆瓣上获取我的观影信息
    def get_douban_infos(self, username):

        url_que = queue.Queue()
        url_que.put('https://movie.douban.com/people/' + username + '/collect?sort=time&amp;start=0&amp;filter=all&amp;mode=list&amp;tags_sort=count')
        while not url_que.empty():
            url = url_que.get()
            #爬取第一页
            html_doc = BeautifulSoup(self.get_html(url), 'html.parser')

            #获取下一页链接
            next_url = html_doc.select('#content > div.grid-16-8.clearfix > div.article > div.paginator > span.next > a')
            if len(next_url) > 0:
                next_url = next_url[0]['href']
                url_que.put(next_url)

            html_doc = BeautifulSoup(self.get_html(url), 'html.parser')
            li_lists = html_doc.select('#content > div')[1].select('div.article > ul > li')

            for li in li_lists:

                a_label = li.select('div.item-show > div > a')[0]

                movie_name = a_label.getText().strip()
                movie_name = movie_name.split('/')[0].strip()

                #去重
                query = 'SELECT COUNT(*) FROM douban_movie WHERE movie_name = (%s)'
                self.cursor.execute(query, (movie_name,))
                self.conn.commit()
                res = self.cursor.fetchall()
                if not res[0][0] == 0:
                    continue

                movie_detail_url = a_label['href']
                print(movie_detail_url)
                try:
                    movie_info = self.get_movie_infos(movie_detail_url)
                except TypeError as e:
                    print(str(e))
                    print(movie_name)
                    continue

                rate = li.select('div.item-show > div')[1].select('span')
                if len(rate) == 0:
                    rate = ''
                else:
                    rate = str(rate[0]['class'])
                    regx = re.compile('(\d)')
                    rate = regx.findall(rate)[0]

                watch_time = li.select('div.item-show > div')[1].getText().strip()

                comment = li.select('div.comment')
                #如果有评论
                if len(comment) > 0:
                    comment = comment[0].getText().strip()
                    if not comment.find('(1 有用)') == -1:
                        comment = comment.split(' ')[0].strip()
                else:
                    comment = ''

                #过滤emoij。。。
                regx = re.compile("[dc00-\udfff|\，]+")
                comment = ''.join(regx.findall(comment))
                print(movie_info)

                movie_types = movie_info['类型']
                movie_language = movie_info['语言']
                movie_country = movie_info['制片国家/地区']
                movie_director = movie_info['导演']

                print(comment)
                query = 'INSERT INTO douban_movie(movie_name, rate, watch_time, comment, movie_types, movie_language, movie_country, movie_director) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)'
                self.cursor.execute(query, (movie_name, rate, watch_time, comment, movie_types, movie_language, movie_country, movie_director))
                self.conn.commit()
        return

    #将电影类型分类展示在柱状图中并统计数量
    def show_types_in_column(self, workbook):

        worksheet = workbook.add_worksheet()

        chart = workbook.add_chart({'type' : 'column'})

        query = 'SELECT movie_name, movie_types FROM douban_movie'
        self.cursor.execute(query)
        self.conn.commit()
        movies_lists = self.cursor.fetchall()

        movie_types_dict = {}

        for movie in movies_lists:
            movie_name, movie_types = movie
            types = movie_types.split('/')
            for type in types:
                type = type.strip()
                if type in movie_types_dict:
                    movie_types_dict[type] += 1
                else:
                    movie_types_dict.update({type : 1})

        # Add table data
        table_data = [['类型', '片数'],]
        for key, val in movie_types_dict.items():
            table_data.append([key, val])

        type = '类型'
        num = '数目'
        worksheet.write_column('A1', type)
        worksheet.write_column('B1', num)
        worksheet.write_column('A2', movie_types_dict.keys())
        worksheet.write_column('B2', movie_types_dict.values())

        chart.add_series({'name' : '影片数目',
                          'categories' : ['Sheet1', 1, 0, 1+len(movie_types_dict.keys()), 0],
                          'values' : ['Sheet1', 1, 1, 1+len(movie_types_dict.values()), 1],
                          'color' : 'red',
                          'data_labels' : {'value' : True}})

        #设置X轴属性
        chart.set_x_axis({
            'name' : '影片类型',
            'name_font' : {'size' : 14, 'bold' : False},
            'num_font' : {'size' : 12},
            'line' : {'none' : True},
            'major_gridlines' : {
                'visible' : True,
                'line' : {'width' : 1.5, 'dash_type' : 'dash'}
            },
            'text_axis' : True
        })

        #设置长宽
        chart.set_size({
            'x_scale' : 2.5,
            'y_scale' : 2
        })

        #设置标题
        chart.set_title({
            'name' : '15/07/01 - 16/06/30 观影类型统计'
        })

        #设置属性块
        chart.set_legend({
            'position' : 'left'
        })

        #图下方显示表格
        chart.set_table({
            'show_keys' : True,
            'font' : {'size' : 12}
        })

        worksheet.insert_chart('C1', chart)

    #将电影语言分类展示在饼状图中
    def show_languages_in_pie(self, workbook):

        worksheet = workbook.add_worksheet()

        chart = workbook.add_chart({'type' : 'pie'})

        query = 'SELECT movie_name, movie_language FROM douban_movie'
        self.cursor.execute(query)
        self.conn.commit()
        movies_lists = self.cursor.fetchall()

        movie_languages_dict = dict({})

        for movie in movies_lists:
            movie_name, movie_languages = movie
            languages = movie_languages.split('/')

            for language in languages:
                language = language.strip()
                if language in movie_languages_dict:
                    movie_languages_dict[language] += 1
                else:
                    movie_languages_dict.update({language : 1})

        total_sum = 0
        for key, val in movie_languages_dict.items():
            total_sum += val

        percent_lists = []
        # Add table data
        table_data = [['语言', '数目', '百分比'],]
        for key, val in movie_languages_dict.items():
            movie_languages_dict[key] = val
            tmp = format(val/total_sum, '.2%')
            percent_lists.append(tmp)
            table_data.append([key, val, tmp])

        language = '语言'
        num = '数目'
        percent = '百分比'

        worksheet.write_column('A1', language)
        worksheet.write_column('B1', num)
        worksheet.write_column('C1', percent)

        worksheet.write_column('A2', movie_languages_dict.keys())
        worksheet.write_column('B2', movie_languages_dict.values())
        worksheet.write_column('C2', percent_lists)

        chart.add_series({'name' : '影片语言',
                          'categories' : ['Sheet2', 1, 0, 1+len(movie_languages_dict.keys()), 0],
                          'values' : ['Sheet2', 1, 1, 1+len(movie_languages_dict.values()), 1],
                          'color' : 'red',
                          'data_labels' : {'percentage' : True}})

        #设置长宽
        chart.set_size({
            'x_scale' : 1.5,
            'y_scale' : 2
        })

        #设置标题
        chart.set_title({
            'name' : '15/07/01 - 16/06/30 观影语言统计'
        })

        #设置属性块
        chart.set_legend({
            'position' : 'bottom'
        })

        worksheet.insert_chart('D1', chart)

    #统计每个月观看电影数量并绘制趋势图
    def show_monthly_watched_movies_num(self, workbook):
        worksheet = workbook.add_worksheet()

        chart = workbook.add_chart({'type' : 'line'})

        query = 'SELECT movie_name, watch_time FROM douban_movie'
        self.cursor.execute(query)
        self.conn.commit()
        movies_lists = self.cursor.fetchall()

        movie_monthly_dict = dict({})

        for movie in movies_lists:
            movie_name, watch_time = movie
            watch_time = datetime.datetime.strptime(str(watch_time), "%Y-%m-%d %H:%M:%S")
            key = str(watch_time.year) + '-' + str(watch_time.month)
            if key in movie_monthly_dict:
                movie_monthly_dict[key] += 1
            else:
                movie_monthly_dict.update({key : 1})

        movie_monthly_list = sorted(movie_monthly_dict.items(), key=lambda d: d[0])

        time_list = []
        num_list = []

        # Add table data
        table_data = [['时间', '数目'],]
        for key, val in movie_monthly_list:
            table_data.append([key, val])
            time_list.append(key)
            num_list.append(val)

        watch_time = '时间'
        num = '数目'

        worksheet.write_column('A1', watch_time)
        worksheet.write_column('B1', num)

        worksheet.write_column('A2', time_list)
        worksheet.write_column('B2', num_list)

        chart.add_series({'name' : '观影数目',
                          'categories' : ['Sheet3', 1, 0, 1+len(movie_monthly_dict.keys()), 0],
                          'values' : ['Sheet3', 1, 1, 1+len(movie_monthly_dict.values()), 1],
                          'color' : 'red',
                          'marker' : {'type' : 'diamond'},
                          'smooth' : 'True',
                          'data_labels' : {'value' : True}})

        #设置长宽
        chart.set_size({
            'x_scale' : 1.5,
            'y_scale' : 2
        })

        #设置标题
        chart.set_title({
            'name' : '15/07/01 - 16/06/30 观影时间统计'
        })

        #设置属性块
        chart.set_legend({
            'position' : 'bottom'
        })

        #图下方显示表格
        chart.set_table({
            'show_keys' : True,
            'font' : {'size' : 12}
        })

        worksheet.insert_chart('C1', chart)

    #数据可视化展示
    def show_datas(self):

        workbook = xlsxwriter.Workbook('G:\\chart.xlsx')

        #统计分类信息
        self.show_types_in_column(workbook)

        #统计语言信息
        self.show_languages_in_pie(workbook)

        #统计月观影片数
        self.show_monthly_watched_movies_num(workbook)

        workbook.close()

    def execute_vba(self):
        import pychart_into_img
        pychart_into_img.main()

def main():
    crawler = Crawler()

    username = input('enter your douban username:')
    crawler.get_douban_infos(username)

    crawler.show_datas()

    crawler.execute_vba()

if __name__ == "__main__":
    main()

{% endhighlight %}
    
按照赋比兴的老套路，我也得放点感想在这里才显得逼格高啊hhhhh。
    
想一想豆瓣作为一个典型的文艺青年聚集地曾经社区那么活跃，如今已经衰落到“门前冷落鞍马稀”了，我想在互联网行业日新月异的今天，豆瓣几年来几乎一成不变，呈现出一种拒绝变化的姿态很难说不是衰落的一方面原因，拥有那么多数据为什么不多多服务人民群众，拥抱一下大数据呢？
    
最近在YY买台云主机，把博客搭建到服务器上，以后造出来的一些轮子也可以服务大众了，比如把这个做成一个小轮子，方便电影爱好者对自己的观影数据有一个直观的认知。